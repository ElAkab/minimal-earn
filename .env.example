# ======================
# CONFIGURATION IA
# ======================

# Provider IA à utiliser
# Valeurs possibles: "ollama" (local, gratuit) ou "openrouter" (externe, rapide, peu cher)
# Par défaut: ollama
AI_PROVIDER=ollama

# API Keys pour providers externes (seulement si AI_PROVIDER != ollama)
# OpenRouter: https://openrouter.ai (recommandé pour production)
# OPENROUTER_API_KEY=sk-or-v1-...

# OpenAI: https://platform.openai.com
# OPENAI_API_KEY=sk-...

# Anthropic: https://console.anthropic.com
# ANTHROPIC_API_KEY=sk-ant-...

# ======================
# CONFIGURATION OLLAMA
# ======================

# Timeout pour les requêtes Ollama (en millisecondes)
# 0 = pas de timeout (recommandé pour développement local)
# 30000 = 30 secondes (production)
OLLAMA_TIMEOUT=0

# ======================
# CONFIGURATION SERVEUR
# ======================

# Port du serveur backend
PORT=5000

# ======================
# NOTES
# ======================

# Pour utiliser Ollama (IA locale gratuite):
# 1. Installer Ollama: https://ollama.ai
# 2. Télécharger les modèles: 
#    ollama pull gpt-oss
#    ollama pull hir0rameel/qwen-claude
# 3. Démarrer Ollama: ollama serve
# 4. AI_PROVIDER=ollama (déjà configuré par défaut)

# Pour utiliser OpenRouter (IA externe rapide):
# 1. Créer un compte sur https://openrouter.ai
# 2. Obtenir une API key
# 3. Décommenter et remplir OPENROUTER_API_KEY ci-dessus
# 4. Changer AI_PROVIDER=openrouter

# Recommandations:
# - Développement: Ollama (gratuit, privé, mais plus lent)
# - Production: OpenRouter (rapide, peu cher, ~$0.0001/requête)
